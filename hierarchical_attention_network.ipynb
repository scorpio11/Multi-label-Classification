{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hierarchical_attention_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85-8U047-lrZ",
        "outputId": "205493d0-971f-4e51-c1ab-f085070c3904"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3zsu0GM-n5z",
        "outputId": "01ae61b7-8fdc-4f26-ca61-8cf4fbb33a9d"
      },
      "source": [
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D, SimpleRNN\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
        "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.initializers import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "from keras.callbacks import *\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn import metrics\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTv4ivxI-prG",
        "outputId": "67f01742-f744-4daa-acec-7232554fa8fe"
      },
      "source": [
        "rcv1_train = pd.read_csv(\"/content/drive/MyDrive/ReutersTextClassification/Datasets/RCV1/rcv1_train_data_formatted.csv\")\n",
        "rcv1_test=pd.read_csv(\"/content/drive/MyDrive/ReutersTextClassification/Datasets/RCV1/rcv1_test_data_formatted.csv\")\n",
        "\n",
        "codes=[]\n",
        "with open('/content/drive/MyDrive/ReutersTextClassification/Datasets/RCV1/rcv1.topics.txt','r') as f:\n",
        "  lines=f.readlines()\n",
        "  for line in lines:\n",
        "    codes.append(line.rstrip())\n",
        "print(len(codes))\n",
        "print(codes)\n",
        "\n",
        "\n",
        "rcv1_train_labels = rcv1_train[codes]\n",
        "rcv1_test_labels = rcv1_test[codes]\n",
        "\n",
        "Y = rcv1_train_labels.values\n",
        "Y_test = rcv1_test_labels.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103\n",
            "['C11', 'C12', 'C13', 'C14', 'C15', 'C151', 'C1511', 'C152', 'C16', 'C17', 'C171', 'C172', 'C173', 'C174', 'C18', 'C181', 'C182', 'C183', 'C21', 'C22', 'C23', 'C24', 'C31', 'C311', 'C312', 'C313', 'C32', 'C33', 'C331', 'C34', 'C41', 'C411', 'C42', 'CCAT', 'E11', 'E12', 'E121', 'E13', 'E131', 'E132', 'E14', 'E141', 'E142', 'E143', 'E21', 'E211', 'E212', 'E31', 'E311', 'E312', 'E313', 'E41', 'E411', 'E51', 'E511', 'E512', 'E513', 'E61', 'E71', 'ECAT', 'G15', 'G151', 'G152', 'G153', 'G154', 'G155', 'G156', 'G157', 'G158', 'G159', 'GCAT', 'GCRIM', 'GDEF', 'GDIP', 'GDIS', 'GENT', 'GENV', 'GFAS', 'GHEA', 'GJOB', 'GMIL', 'GOBIT', 'GODD', 'GPOL', 'GPRO', 'GREL', 'GSCI', 'GSPO', 'GTOUR', 'GVIO', 'GVOTE', 'GWEA', 'GWELF', 'M11', 'M12', 'M13', 'M131', 'M132', 'M14', 'M141', 'M142', 'M143', 'MCAT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1NsEa09-2Vl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d9e48a-48b0-4240-e801-3303f0ea1d9a"
      },
      "source": [
        "print('average train sentence length: ', rcv1_train.newsitem.str.split().str.len().mean())\n",
        "print('stdev train sentence length: ', rcv1_train.newsitem.str.split().str.len().std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average train sentence length:  222.89727418031018\n",
            "stdev train sentence length:  201.0941646168312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZIVMr1a-3J7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834b849d-9bea-4611-846c-b78889893548"
      },
      "source": [
        "print('average test sentence length: ', rcv1_test.newsitem.str.split().str.len().mean())\n",
        "print('stdev test sentence length: ', rcv1_test.newsitem.str.split().str.len().std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average test sentence length:  230.09108351754406\n",
            "stdev test sentence length:  208.92326731703892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "merYGtGak3XA"
      },
      "source": [
        "MAX_WORDS_PER_SENT = 100\n",
        "MAX_SENT = 15\n",
        "MAX_VOC_SIZE = 20000\n",
        "#GLOVE_DIM = 100\n",
        "TEST_SPLIT = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3E0ZcpM8gQS"
      },
      "source": [
        "# Do some basic cleaning of the review text\n",
        "def remove_quotations(text):\n",
        "    \"\"\"\n",
        "    Remove quotations and slashes from the dataset.\n",
        "    \"\"\"\n",
        "    text = re.sub(r\"\\\\\", \"\", str(text))\n",
        "    text = re.sub(r\"\\'\", \"\", str(text))\n",
        "    text = re.sub(r\"\\\"\", \"\", str(text))\n",
        "    return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97g_EEoC9Umc"
      },
      "source": [
        "rcv1_train['newsitem'] = rcv1_train['newsitem'].apply(remove_quotations)\n",
        "rcv1_test['newsitem'] = rcv1_test['newsitem'].apply(remove_quotations)\n",
        "\n",
        "rcv1_train['newsitem'] = rcv1_train['newsitem'].apply(lambda x: x.strip().lower())\n",
        "rcv1_test['newsitem'] = rcv1_test['newsitem'].apply(lambda x: x.strip().lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg_89kXa9lgw",
        "outputId": "32ae4bc3-5983-4a14-9ca3-de9c7a11fcb4"
      },
      "source": [
        "import gc\n",
        "# Get the data and the sentiment\n",
        "news = rcv1_train['newsitem'].values\n",
        "target = rcv1_train_labels.values\n",
        "\n",
        "news_test = rcv1_test['newsitem'].values\n",
        "target_test = rcv1_test_labels.values\n",
        "\n",
        "del rcv1_train\n",
        "del rcv1_test\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXaWqzYY9-dC"
      },
      "source": [
        "# Build a Keras Tokenizer that can encode every token\n",
        "word_tokenizer = Tokenizer(num_words=MAX_VOC_SIZE)\n",
        "word_tokenizer.fit_on_texts(news)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EikGFZp8-Ce6"
      },
      "source": [
        "# Construct the input matrix. This should be a nd-array of\n",
        "# shape (n_samples, MAX_SENT, MAX_WORDS_PER_SENT).\n",
        "# We zero-pad this matrix (this does not influence\n",
        "# any predictions due to the attention mechanism.\n",
        "X = np.zeros((len(news), MAX_SENT, MAX_WORDS_PER_SENT), dtype='int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM_LtBSH-6vV"
      },
      "source": [
        "#for test set\n",
        "X_test = np.zeros((len(news_test), MAX_SENT, MAX_WORDS_PER_SENT), dtype='int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0vZIEo9-TPN",
        "outputId": "4c6cf5da-60e3-4da5-e214-79b962f591a5"
      },
      "source": [
        "nltk.download('punkt')\n",
        "for i, single_news in enumerate(news):\n",
        "    sentences = sent_tokenize(single_news)\n",
        "    tokenized_sentences = word_tokenizer.texts_to_sequences(\n",
        "        sentences\n",
        "    )\n",
        "    tokenized_sentences = pad_sequences(\n",
        "        tokenized_sentences, maxlen=MAX_WORDS_PER_SENT\n",
        "    )\n",
        "\n",
        "    pad_size = MAX_SENT - tokenized_sentences.shape[0]\n",
        "\n",
        "    if pad_size < 0:\n",
        "        tokenized_sentences = tokenized_sentences[0:MAX_SENT]\n",
        "    else:\n",
        "        tokenized_sentences = np.pad(\n",
        "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
        "            mode='constant', constant_values=0\n",
        "        )\n",
        "\n",
        "    # Store this observation as the i-th observation in\n",
        "    # the data matrix\n",
        "    X[i] = tokenized_sentences[None, ...]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xS6BT_p_CJc"
      },
      "source": [
        "#for test set\n",
        "for i, single_news in enumerate(news_test):\n",
        "    sentences = sent_tokenize(single_news)\n",
        "    tokenized_sentences_test = word_tokenizer.texts_to_sequences(\n",
        "        sentences\n",
        "    )\n",
        "    tokenized_sentences_test = pad_sequences(\n",
        "        tokenized_sentences_test, maxlen=MAX_WORDS_PER_SENT\n",
        "    )\n",
        "\n",
        "    pad_size = MAX_SENT - tokenized_sentences_test.shape[0]\n",
        "\n",
        "    if pad_size < 0:\n",
        "        tokenized_sentences_test = tokenized_sentences_test[0:MAX_SENT]\n",
        "    else:\n",
        "        tokenized_sentences_test = np.pad(\n",
        "            tokenized_sentences_test, ((0, pad_size), (0, 0)),\n",
        "            mode='constant', constant_values=0\n",
        "        )\n",
        "\n",
        "    # Store this observation as the i-th observation in\n",
        "    # the data matrix\n",
        "    X_test[i] = tokenized_sentences_test[None, ...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgAeiwpZ-gpK"
      },
      "source": [
        "# Transform the labels into a format Keras can handle\n",
        "y = np.asarray(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kJ3RDAY_eO0"
      },
      "source": [
        "# Transform the labels into a format Keras can handle\n",
        "y_test = np.asarray(target_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR44ZLuE-rcu"
      },
      "source": [
        "# We make a train/test split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=TEST_SPLIT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N04h6M_3--Cw"
      },
      "source": [
        "word_index = word_tokenizer.word_index\n",
        "max_features = len(word_index)+1\n",
        "def load_glove(word_index):\n",
        "    EMBEDDING_FILE = '/content/drive/MyDrive/ReutersTextClassification/WordEmbedding/Glove_6B/glove.6B.300d.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if o.split(\" \")[0] in word_index)\n",
        "\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "            \n",
        "    return embedding_matrix \n",
        "\n",
        "def load_fasttext(word_index):    \n",
        "    EMBEDDING_FILE = '/content/drive/MyDrive/ReutersTextClassification/WordEmbedding/Fasttext/wiki-news-300d-1M.vec'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100 and o.split(\" \")[0] in word_index )\n",
        "\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def load_para(word_index):\n",
        "    EMBEDDING_FILE = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100 and o.split(\" \")[0] in word_index)\n",
        "\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "    embed_size = all_embs.shape[1]\n",
        "    \n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "    \n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qqq7M2c-_t_",
        "outputId": "ad5496fb-fcb7-4987-9c8d-ee8e4d48ca49"
      },
      "source": [
        "embedding_matrix = load_glove(word_index)\n",
        "#embedding_matrix_2 = load_fasttext(word_index)\n",
        "#embedding_matrix_3 = load_para(word_index)\n",
        "#embedding_matrix = np.mean((embedding_matrix_1, embedding_matrix_3), axis=0)  \n",
        "#del embedding_matrix_1, embedding_matrix_3\n",
        "gc.collect()\n",
        "np.shape(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77961, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DBgoqlg_yyY"
      },
      "source": [
        "from tensorflow import keras\n",
        "class AttentionLayer(keras.layers.Layer):\n",
        "    def __init__(self, context_vector_length=100, **kwargs):\n",
        "        \"\"\"\n",
        "        An implementation of a attention layer. This layer\n",
        "        accepts a 3d Tensor (batch_size, time_steps, input_dim) and\n",
        "        applies a single layer attention mechanism in the time\n",
        "        direction (the second axis).\n",
        "        :param context_vector_lenght: (int) The size of the hidden context vector.\n",
        "            If set to 1 this layer reduces to a standard attention layer.\n",
        "        :param kwargs: Any argument that the baseclass Layer accepts.\n",
        "        \"\"\"\n",
        "        self.context_vector_length = context_vector_length\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = input_shape[2]\n",
        "\n",
        "        # Add a weights layer for the\n",
        "        self.W = self.add_weight(\n",
        "            name='W', shape=(dim, self.context_vector_length),\n",
        "            initializer=keras.initializers.get('uniform'),\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        self.u = self.add_weight(\n",
        "            name='context_vector', shape=(self.context_vector_length, 1),\n",
        "            initializer=keras.initializers.get('uniform'),\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def _get_attention_weights(self, X):\n",
        "        \"\"\"\n",
        "        Computes the attention weights for each timestep in X\n",
        "        :param X: 3d-tensor (batch_size, time_steps, input_dim)\n",
        "        :return: 2d-tensor (batch_size, time_steps) of attention weights\n",
        "        \"\"\"\n",
        "        # Compute a time-wise stimulus, i.e. a stimulus for each\n",
        "        # time step. For this first compute a hidden layer of\n",
        "        # dimension self.context_vector_length and take the\n",
        "        # similarity of this layer with self.u as the stimulus\n",
        "        u_tw = K.tanh(K.dot(X, self.W))\n",
        "        tw_stimulus = K.dot(u_tw, self.u)\n",
        "\n",
        "        # Remove the last axis an apply softmax to the stimulus to\n",
        "        # get a probability.\n",
        "        tw_stimulus = K.reshape(tw_stimulus, (-1, tw_stimulus.shape[1]))\n",
        "        att_weights = K.softmax(tw_stimulus)\n",
        "\n",
        "        return att_weights\n",
        "\n",
        "    def call(self, X):\n",
        "        att_weights = self._get_attention_weights(X)\n",
        "\n",
        "        # Reshape the attention weights to match the dimensions of X\n",
        "        att_weights = K.reshape(att_weights, (-1, att_weights.shape[1], 1))\n",
        "        att_weights = K.repeat_elements(att_weights, X.shape[-1], -1)\n",
        "\n",
        "        # Multiply each input by its attention weights\n",
        "        weighted_input = keras.layers.Multiply()([X, att_weights])\n",
        "\n",
        "        # Sum in the direction of the time-axis.\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[2]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'context_vector_length': self.context_vector_length\n",
        "        }\n",
        "        base_config = super(AttentionLayer, self).get_config()\n",
        "        return {**base_config, **config}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2S1nc7p_zdf"
      },
      "source": [
        "class HAN(Model):\n",
        "    def __init__(\n",
        "            self, max_words, max_sentences, output_size,\n",
        "            embedding_matrix, word_encoding_dim=300,\n",
        "            sentence_encoding_dim=300, inputs=None,\n",
        "            outputs=None, name='han-for-docla'\n",
        "    ):\n",
        "        \"\"\"\n",
        "        A Keras implementation of Hierarchical Attention networks\n",
        "        for document classification.\n",
        "        :param max_words: The maximum number of words per sentence\n",
        "        :param max_sentences: The maximum number of sentences\n",
        "        :param output_size: The dimension of the last layer (i.e.\n",
        "            the number of classes you wish to predict)\n",
        "        :param embedding_matrix: The embedding matrix to use for\n",
        "            representing words\n",
        "        :param word_encoding_dim: The dimension of the GRU\n",
        "            layer in the word encoder.\n",
        "        :param sentence_encoding_dim: The dimension of the GRU\n",
        "            layer in the sentence encoder.\n",
        "        \"\"\"\n",
        "        self.max_words = max_words\n",
        "        self.max_sentences = max_sentences\n",
        "        self.output_size = output_size\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "        self.word_encoding_dim = word_encoding_dim\n",
        "        self.sentence_encoding_dim = sentence_encoding_dim\n",
        "\n",
        "        in_tensor, out_tensor = self._build_network()\n",
        "\n",
        "        super(HAN, self).__init__(\n",
        "            inputs=in_tensor, outputs=out_tensor, name=name\n",
        "        )\n",
        "\n",
        "    def build_word_encoder(self, max_words, embedding_matrix, encoding_dim=200):\n",
        "        \"\"\"\n",
        "        Build the model that embeds and encodes in context the\n",
        "        words used in a sentence. The return model takes a tensor of shape\n",
        "        (batch_size, max_length) that represents a collection of sentences\n",
        "        and returns an encoded representation of these sentences.\n",
        "        :param max_words: (int) The maximum sentence length this model accepts\n",
        "        :param embedding_matrix: (2d array-like) A matrix with the i-th row\n",
        "            representing the embedding of the word represented by index i.\n",
        "        :param encoding_dim: (int, should be even) The dimension of the\n",
        "            bidirectional encoding layer. Half of the nodes are used in the\n",
        "            forward direction and half in the backward direction.\n",
        "        :return: Instance of keras.Model\n",
        "        \"\"\"\n",
        "        assert encoding_dim % 2 == 0, \"Embedding dimension should be even\"\n",
        "\n",
        "        vocabulary_size = embedding_matrix.shape[0]\n",
        "        embedding_dim = embedding_matrix.shape[1]\n",
        "\n",
        "        embedding_layer = Embedding(\n",
        "            vocabulary_size, embedding_dim,\n",
        "            weights=[embedding_matrix], input_length=max_words,\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        sentence_input = Input(shape=(max_words,), dtype='int32')\n",
        "        embedded_sentences = embedding_layer(sentence_input)\n",
        "        encoded_sentences = Bidirectional(\n",
        "            GRU(int(encoding_dim / 2), return_sequences=True)\n",
        "        )(embedded_sentences)\n",
        "\n",
        "        return Model(\n",
        "            inputs=[sentence_input], outputs=[encoded_sentences], name='word_encoder'\n",
        "        )\n",
        "\n",
        "    def build_sentence_encoder(self, max_sentences, summary_dim, encoding_dim=200):\n",
        "        \"\"\"\n",
        "        Build the encoder that encodes the vector representation of\n",
        "        sentences in their context.\n",
        "        :param max_sentences: The maximum number of sentences that can be\n",
        "            passed. Use zero-padding to supply shorter sentences.\n",
        "        :param summary_dim: (int) The dimension of the vectors that summarizes\n",
        "            sentences. Should be equal to the encoding_dim of the word\n",
        "            encoder.\n",
        "        :param encoding_dim: (int, even) The dimension of the vector that\n",
        "            summarizes sentences in context. Half is used in forward direction,\n",
        "            half in backward direction.\n",
        "        :return: Instance of keras.Model\n",
        "        \"\"\"\n",
        "        assert encoding_dim % 2 == 0, \"Embedding dimension should be even\"\n",
        "\n",
        "        text_input = Input(shape=(max_sentences, summary_dim))\n",
        "        encoded_sentences = Bidirectional(\n",
        "            GRU(int(encoding_dim / 2), return_sequences=True)\n",
        "        )(text_input)\n",
        "        return Model(\n",
        "            inputs=[text_input], outputs=[encoded_sentences], name='sentence_encoder'\n",
        "        )\n",
        "\n",
        "    def _build_network(self):\n",
        "        \"\"\"\n",
        "        Build the graph that represents this network\n",
        "        :return: in_tensor, out_tensor, Tensors representing the input and output\n",
        "            of this network.\n",
        "        \"\"\"\n",
        "        in_tensor = Input(shape=(self.max_sentences, self.max_words))\n",
        "\n",
        "        word_encoder = self.build_word_encoder(\n",
        "            self.max_words, self.embedding_matrix, self.word_encoding_dim\n",
        "        )\n",
        "\n",
        "        word_rep = TimeDistributed(\n",
        "            word_encoder, name='word_encoder'\n",
        "        )(in_tensor)\n",
        "\n",
        "        # Sentence Rep is a 3d-tensor (batch_size, max_sentences, word_encoding_dim)\n",
        "        sentence_rep = TimeDistributed(\n",
        "            AttentionLayer(), name='word_attention'\n",
        "        )(word_rep)\n",
        "\n",
        "        doc_rep = self.build_sentence_encoder(\n",
        "            self.max_sentences, self.word_encoding_dim, self.sentence_encoding_dim\n",
        "        )(sentence_rep)\n",
        "\n",
        "        # We get the final representation by applying our attention mechanism\n",
        "        # to the encoded sentences\n",
        "        doc_summary = AttentionLayer(name='sentence_attention')(doc_rep)\n",
        "\n",
        "        out_tensor = Dense(\n",
        "            self.output_size, activation='sigmoid', name='class_prediction'\n",
        "        )(doc_summary)\n",
        "\n",
        "        return in_tensor, out_tensor\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'max_words': self.max_words,\n",
        "            'max_sentences': self.max_sentences,\n",
        "            'output_size': self.output_size,\n",
        "            'embedding_matrix': self.embedding_matrix,\n",
        "            'word_encoding_dim': self.word_encoding_dim,\n",
        "            'sentence_encoding_dim': self.sentence_encoding_dim,\n",
        "            'base_config': super(HAN, self).get_config()\n",
        "        }\n",
        "\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config, custom_objects=None):\n",
        "        \"\"\"\n",
        "        Keras' API isn't really extendible at this point\n",
        "        therefore we need to use a bit hacky solution to\n",
        "        be able to correctly reconstruct the HAN model\n",
        "        from a config. This therefore does not reconstruct\n",
        "        a instance of HAN model, but actually a standard\n",
        "        Keras model that behaves exactly the same.\n",
        "        \"\"\"\n",
        "        base_config = config.pop('base_config')\n",
        "\n",
        "        return Model.from_config(\n",
        "            base_config, custom_objects=custom_objects\n",
        "        )\n",
        "\n",
        "    def predict_sentence_attention(self, X):\n",
        "        \"\"\"\n",
        "        For a given set of texts predict the attention\n",
        "        weights for each sentence.\n",
        "        :param X: 3d-tensor, similar to the input for predict\n",
        "        :return: 2d array (num_obs, max_sentences) containing\n",
        "            the attention weights for each sentence\n",
        "        \"\"\"\n",
        "        att_layer = self.get_layer('sentence_attention')\n",
        "        prev_tensor = att_layer.input\n",
        "\n",
        "        # Create a temporary dummy layer to hold the\n",
        "        # attention weights tensor\n",
        "        dummy_layer = Lambda(\n",
        "            lambda x: att_layer._get_attention_weights(x)\n",
        "        )(prev_tensor)\n",
        "\n",
        "        return Model(self.input, dummy_layer).predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GQ5BFAmKPyH"
      },
      "source": [
        "han_model = HAN(\n",
        "    MAX_WORDS_PER_SENT, MAX_SENT, len(codes), embedding_matrix,\n",
        "    word_encoding_dim=300, sentence_encoding_dim=300\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWuIlWe_KVho",
        "outputId": "5fa6feda-08e7-4a64-ba20-d2c01eb9cd47"
      },
      "source": [
        "han_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"han-for-docla\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 15, 100)]         0         \n",
            "_________________________________________________________________\n",
            "word_encoder (TimeDistribute (None, 15, 100, 300)      23795100  \n",
            "_________________________________________________________________\n",
            "word_attention (TimeDistribu (None, 15, 300)           30100     \n",
            "_________________________________________________________________\n",
            "sentence_encoder (Functional (None, 15, 300)           406800    \n",
            "_________________________________________________________________\n",
            "sentence_attention (Attentio (None, 300)               30100     \n",
            "_________________________________________________________________\n",
            "class_prediction (Dense)     (None, 103)               31003     \n",
            "=================================================================\n",
            "Total params: 24,293,103\n",
            "Trainable params: 24,293,103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO7mAYt-pVg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74b7ae9e-c411-4078-d0ae-8bca89c5f90b"
      },
      "source": [
        "\n",
        "han_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "filepath='/content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f'\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=1, min_lr=0.0001, verbose=2)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=3, verbose=2, mode='auto')\n",
        "\n",
        "callbacks = [checkpoint, earlystopping, reduce_lr]\n",
        "\n",
        "print(\"model fitting - Hierachical attention network\")\n",
        "history=han_model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=100, batch_size=64,callbacks=callbacks)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model fitting - Hierachical attention network\n",
            "Epoch 1/100\n",
            "579/579 [==============================] - 989s 2s/step - loss: 0.6317 - accuracy: 2.1290e-05 - val_loss: 0.4663 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.46627, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "579/579 [==============================] - 1149s 2s/step - loss: 0.4228 - accuracy: 4.9382e-05 - val_loss: 0.3126 - val_accuracy: 0.0050\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.46627 to 0.31262, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/100\n",
            "579/579 [==============================] - 1179s 2s/step - loss: 0.2868 - accuracy: 0.0040 - val_loss: 0.2263 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.31262 to 0.22627, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/100\n",
            "579/579 [==============================] - 1259s 2s/step - loss: 0.2129 - accuracy: 0.0049 - val_loss: 0.1816 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.22627 to 0.18158, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/100\n",
            "579/579 [==============================] - 1541s 3s/step - loss: 0.1742 - accuracy: 0.0040 - val_loss: 0.1572 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.18158 to 0.15723, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/100\n",
            "579/579 [==============================] - 1098s 2s/step - loss: 0.1527 - accuracy: 0.0041 - val_loss: 0.1428 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.15723 to 0.14284, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/100\n",
            "579/579 [==============================] - 1104s 2s/step - loss: 0.1400 - accuracy: 0.0045 - val_loss: 0.1337 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.14284 to 0.13368, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/100\n",
            "579/579 [==============================] - 1276s 2s/step - loss: 0.1319 - accuracy: 0.0045 - val_loss: 0.1275 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.13368 to 0.12751, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/100\n",
            "579/579 [==============================] - 1246s 2s/step - loss: 0.1258 - accuracy: 0.0050 - val_loss: 0.1231 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.12751 to 0.12314, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/100\n",
            "579/579 [==============================] - 1567s 3s/step - loss: 0.1218 - accuracy: 0.0050 - val_loss: 0.1199 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.12314 to 0.11993, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/100\n",
            "579/579 [==============================] - 1328s 2s/step - loss: 0.1191 - accuracy: 0.0039 - val_loss: 0.1175 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.11993 to 0.11749, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/100\n",
            "579/579 [==============================] - 1196s 2s/step - loss: 0.1165 - accuracy: 0.0043 - val_loss: 0.1156 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.11749 to 0.11560, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/100\n",
            "579/579 [==============================] - 1527s 3s/step - loss: 0.1150 - accuracy: 0.0044 - val_loss: 0.1141 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.11560 to 0.11410, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/100\n",
            "579/579 [==============================] - 1305s 2s/step - loss: 0.1134 - accuracy: 0.0036 - val_loss: 0.1129 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.11410 to 0.11288, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/100\n",
            "579/579 [==============================] - 1708s 3s/step - loss: 0.1124 - accuracy: 0.0044 - val_loss: 0.1119 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.11288 to 0.11188, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/100\n",
            "579/579 [==============================] - 1247s 2s/step - loss: 0.1116 - accuracy: 0.0051 - val_loss: 0.1110 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.11188 to 0.11105, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/100\n",
            "579/579 [==============================] - 1195s 2s/step - loss: 0.1106 - accuracy: 0.0040 - val_loss: 0.1103 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.11105 to 0.11035, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/100\n",
            "579/579 [==============================] - 1138s 2s/step - loss: 0.1098 - accuracy: 0.0051 - val_loss: 0.1098 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.11035 to 0.10975, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/100\n",
            "579/579 [==============================] - 1292s 2s/step - loss: 0.1091 - accuracy: 0.0042 - val_loss: 0.1092 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.10975 to 0.10924, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/100\n",
            "579/579 [==============================] - 1216s 2s/step - loss: 0.1081 - accuracy: 0.0044 - val_loss: 0.1088 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.10924 to 0.10880, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/100\n",
            "579/579 [==============================] - 1179s 2s/step - loss: 0.1079 - accuracy: 0.0042 - val_loss: 0.1084 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.10880 to 0.10841, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/100\n",
            "579/579 [==============================] - 1319s 2s/step - loss: 0.1080 - accuracy: 0.0042 - val_loss: 0.1081 - val_accuracy: 0.0052\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.10841 to 0.10807, saving model to /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/100\n",
            "424/579 [====================>.........] - ETA: 4:57 - loss: 0.1071 - accuracy: 0.0046"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6e6f0013d8f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model fitting - Hierachical attention network\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR-fq-v__Ko2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvxc5ZAS_LWY"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Models/text_cnn_500_trainabe_true_fasttext.hd5f',custom_objects={\"HAN\":HAN,\"AttentionLayer\":AttentionLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hUORCBF_Noi"
      },
      "source": [
        "predictions=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgktUJns_QJt"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "#delta, _ = bestThresshold(Y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx3nIKH1_QzC"
      },
      "source": [
        "pred_bools = [pl>0.50 for pl in predictions] #boolean output after thresholding\n",
        "\n",
        "#Print and save classification report\n",
        "print('Test F1 Accuracy(Micro): ', f1_score(y_test, pred_bools,average='micro'))\n",
        "print('Test F1 Accuracy(Macro): ', f1_score(y_test, pred_bools,average='macro'))\n",
        "print('Test Flat Accuracy: ', accuracy_score(y_test, pred_bools),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fiy2vjcM_S0C"
      },
      "source": [
        "m = tf.keras.metrics.Precision(top_k=1)\n",
        "m.update_state(Y_test, pred_bools)\n",
        "m.result().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MrUgDXe_UUQ"
      },
      "source": [
        "m = tf.keras.metrics.Precision(top_k=3)\n",
        "m.update_state(Y_test, pred_bools)\n",
        "m.result().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHPs51uI_Xsw"
      },
      "source": [
        "m = tf.keras.metrics.Precision(top_k=5)\n",
        "m.update_state(Y_test, pred_bools)\n",
        "m.result().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}